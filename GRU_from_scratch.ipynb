{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU from scratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tumble-weed/LSTM-from-scratch/blob/master/GRU_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfCdDnSQt780",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKMg4NNHt_Z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len,batch_size,feat_len = 5,32,100\n",
        "seq = np.random.random((seq_len,batch_size,feat_len))\n",
        "seq = torch.tensor(seq).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af-mLc9YuBAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRU(torch.nn.Module):\n",
        "    def __init__(self,input_len,output_len):\n",
        "        \n",
        "        torch.nn.Module.__init__(self)\n",
        "        \n",
        "        hidden_len = output_len\n",
        "        \n",
        "        self.hidden_len = hidden_len\n",
        "        self.output_len = output_len\n",
        "        self.input_len = input_len\n",
        "        #---------------------------------------------------------\n",
        "        # Gates\n",
        "        #---------------------------------------------------------\n",
        "        self.write_gate = torch.nn.Linear(hidden_len,hidden_len)\n",
        "        self.read_gate = torch.nn.Linear(hidden_len,hidden_len)\n",
        "        #---------------------------------------------------------\n",
        "        # fc\n",
        "        #---------------------------------------------------------\n",
        "        self.fc_input = torch.nn.Linear(input_len,output_len)\n",
        "        self.fc_state = torch.nn.Linear(hidden_len,output_len,bias = False)\n",
        "    \n",
        "    def forward(self,x,state):\n",
        "        outs = []\n",
        "        for at_t in x:\n",
        "            read = torch.nn.functional.sigmoid(self.read_gate(state))\n",
        "            write = torch.nn.functional.sigmoid(self.write_gate(state))\n",
        "            \n",
        "            pre_state = self.fc_state(state*read) + self.fc_input(at_t)\n",
        "            state = write*pre_state + (1-write)*state\n",
        "            out = state\n",
        "            outs.append(out)\n",
        "        outs = torch.stack(outs,0)\n",
        "        return outs,state"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}