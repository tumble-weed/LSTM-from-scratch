{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM from scratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tumble-weed/LSTM-from-scratch/blob/master/LSTM_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD_PNY9F-B59",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vB4MXiP-PdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmIpBQ7E-WJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len,batch_size,feat_len = 5,32,100\n",
        "seq = np.random.random((seq_len,batch_size,feat_len))\n",
        "seq = torch.tensor(seq).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXsmXe5q-08X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleRNN(torch.nn.Module):\n",
        "    '''\n",
        "    Assumes the output is the state\n",
        "    has just a single layer that deals with the state and input\n",
        "    '''\n",
        "    def __init__(self,input_len,output_len):\n",
        "        super(SimpleRNN,self).__init__()\n",
        "        \n",
        "        state_len = output_len\n",
        "        \n",
        "        self.input_len,self.output_len,self.state_len = input_len,output_len,state_len\n",
        "        self.fc_input = torch.nn.Linear(input_len,output_len)        \n",
        "        self.fc_state = torch.nn.Linear(state_len,output_len,bias=False)\n",
        "        \n",
        "        pass\n",
        "    \n",
        "    def forward(self,x,state):        \n",
        "        outs = []\n",
        "        for at_t in x:\n",
        "\n",
        "            out = self.fc_input(at_t) + self.fc_state(state)\n",
        "            out = torch.nn.functional.relu(out)\n",
        "            state = out\n",
        "            outs.append(out)\n",
        "        outs = torch.stack(outs,0)\n",
        "        return outs,state\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXNZCSxQANxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_len,output_len = feat_len,9\n",
        "simple_rnn = SimpleRNN(input_len,output_len)\n",
        "hidden = torch.zeros((1,batch_size,output_len))\n",
        "out,state =simple_rnn(seq,hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3Zp58rwBzTf",
        "colab_type": "code",
        "outputId": "d975600b-0d5c-415f-f8d2-4184cffcd133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out.shape,state.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 1, 32, 9]), torch.Size([1, 32, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gct_vAmVCTKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    def __init__(self,):\n",
        "        pass\n",
        "    def forward(self,):\n",
        "        pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlz9yhYOFDfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ProtoLSTM_OutputIsState(torch.nn.Module):\n",
        "    def __init__(self,input_len,output_len):\n",
        "        \n",
        "        torch.nn.Module.__init__(self)\n",
        "        \n",
        "        hidden_len = output_len\n",
        "        \n",
        "        self.hidden_len = hidden_len\n",
        "        self.output_len = output_len\n",
        "        self.input_len = input_len\n",
        "        #---------------------------------------------------------\n",
        "        # Gates\n",
        "        #---------------------------------------------------------\n",
        "        self.remember_state = torch.nn.Linear(hidden_len,hidden_len)\n",
        "        self.remember_input = torch.nn.Linear(input_len,hidden_len,bias=False)\n",
        "        \n",
        "        self.write_state = torch.nn.Linear(hidden_len,hidden_len)\n",
        "        self.write_input = torch.nn.Linear(input_len,hidden_len,bias=False)\n",
        "        \n",
        "        self.read_state = torch.nn.Linear(hidden_len,hidden_len)\n",
        "        self.read_input = torch.nn.Linear(input_len,hidden_len,bias=False)\n",
        "        #---------------------------------------------------------\n",
        "        # fc\n",
        "        #---------------------------------------------------------\n",
        "        self.fc_input = torch.nn.Linear(input_len,output_len)\n",
        "        self.fc_state = torch.nn.Linear(hidden_len,output_len,bias = False)\n",
        "    def forward(self,x,state):\n",
        "        outs = []\n",
        "        for at_t in x:\n",
        "            read = torch.nn.functional.sigmoid(self.read_state(state)+self.read_input(at_t))\n",
        "            write = torch.nn.functional.sigmoid(self.write_state(state)+self.write_input(at_t))\n",
        "            remember = torch.nn.functional.sigmoid(self.remember_state(state)+self.remember_input(at_t))\n",
        "            \n",
        "            pre_state = self.fc_state(state*read) + self.fc_input(at_t)\n",
        "            pre_state = torch.nn.functional.tanh(pre_state)\n",
        "            state = write*pre_state + remember*state\n",
        "            out = state\n",
        "            outs.append(out)\n",
        "        outs = torch.stack(outs,0)\n",
        "        return outs,state\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtseMryVJEj5",
        "colab_type": "code",
        "outputId": "fa39c0fd-52b5-4820-ed50-927762e4f9ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "\n",
        "input_len,output_len = feat_len,9\n",
        "lstm1 = ProtoLSTM_OutputIsState(input_len,output_len)\n",
        "hidden = torch.zeros((1,batch_size,output_len))\n",
        "out,state =lstm1(seq,hidden)\n",
        "print(out.shape,state.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1, 32, 9]) torch.Size([1, 32, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XprVUPfD46Bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRU_OutputIsState(torch.nn.Module):\n",
        "    def __init__(self,input_len,output_len):\n",
        "        \n",
        "        torch.nn.Module.__init__(self)\n",
        "        \n",
        "        hidden_len = output_len\n",
        "        \n",
        "        self.hidden_len = hidden_len\n",
        "        self.output_len = output_len\n",
        "        self.input_len = input_len\n",
        "        #---------------------------------------------------------\n",
        "        # Gates\n",
        "        #---------------------------------------------------------\n",
        "        self.write_gate = torch.nn.Linear(hidden_len,hidden_len)\n",
        "        self.read_gate = torch.nn.Linear(hidden_len,hidden_len)\n",
        "        #---------------------------------------------------------\n",
        "        # fc\n",
        "        #---------------------------------------------------------\n",
        "        self.fc_input = torch.nn.Linear(input_len,output_len)\n",
        "        self.fc_state = torch.nn.Linear(hidden_len,output_len,bias = False)\n",
        "    \n",
        "    def forward(self,x,state):\n",
        "        outs = []\n",
        "        for at_t in x:\n",
        "            read = torch.nn.functional.sigmoid(self.read_gate(state))\n",
        "            write = torch.nn.functional.sigmoid(self.write_gate(state))\n",
        "            \n",
        "            pre_state = self.fc_state(state*read) + self.fc_input(at_t)\n",
        "            state = write*pre_state + (1-write)*state\n",
        "            out = state\n",
        "            outs.append(out)\n",
        "        outs = torch.stack(outs,0)\n",
        "        return outs,state"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}